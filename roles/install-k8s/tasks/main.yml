# The Nodeport Services displayed a failure while network packets cross the default
# network interface on ppc64le-https://jsw.ibm.com/browse/POWERCLOUD-16
# This workaround fixed above failure.
# Follow up task to remove this in future https://jsw.ibm.com/browse/POWERCLOUD-34
- name: Disable tx-checksumming on default network interface
  command: ethtool --offload {{ ansible_default_ipv4['interface'] }} tx-checksumming off
  when:
    - ansible_default_ipv4['interface'] is defined
    - ansible_architecture == 'ppc64le'

- name: Toggle SElinux and swap settings on node
  include_role:
    name: toggle-swap-selinux

# PowerVS has default domainname set as .power-iaas.cloud.ibm.com which is not present in the cloud
- name: Remove domain name from the hostname
  shell: |
    hostnamectl set-hostname $(hostname | cut -d "." -f1)

- name: Install prereq packages
  package:
    name:
      - conntrack-tools
      - socat
      - iproute-tc
      - iptables
    state: present
  when: ansible_pkg_mgr in ['yum', 'dnf']

- name: Install prereq Ubuntu packages
  apt:
    name: "{{ packages }}"
    state: present
  vars:
    packages:
      - conntrack
      - socat
      - iproute2
      - iptables
  when: ansible_pkg_mgr == 'apt'

- name: Template a kubelet service to /usr/lib/systemd/system/kubelet.service
  template:
    src: kubelet.service.j2
    dest: /usr/lib/systemd/system/kubelet.service
    mode: '0644'

- name: Enable and start kubelet
  systemd:
    name: kubelet
    daemon_reexec: true
    state: restarted
    enabled: yes

- name: Generate kubeadm.yaml
  template:
    src: kubeadm.yaml.j2
    dest: /root/kubeadm.yaml
    mode: '0644'

- name: Perform kubeadm init on the control plane node based on LB configuration.
  command: >
    {% if loadbalancer == '' -%}
      kubeadm init --config /root/kubeadm.yaml
    {%- else -%}
      kubeadm init --config /root/kubeadm.yaml --upload-certs
    {%- endif %}
  when: inventory_hostname == groups['masters'][0]


- name: generate join command for HA cluster
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  shell: |
    cert_key=$(kubeadm init phase upload-certs --upload-certs | tail -1)
    kubeadm token create --print-join-command --certificate-key $cert_key
  changed_when: false
  when: groups['masters']|length > 1 and inventory_hostname == groups['masters'][0]
  register: kubernetes_cp_join_command_result

- name: Set the kubeadm join command for control plane nodes globally.
  set_fact:
    kubernetes_cp_join_command: >
      {{ kubernetes_cp_join_command_result.stdout }}
  when: kubernetes_cp_join_command_result.stdout is defined and groups['masters']|length > 1
  delegate_to: "{{ item }}"
  delegate_facts: true
  with_items: "{{ groups['all'] }}"

- name: kubeadm join control plane nodes
  command: "{{ kubernetes_cp_join_command }}"
  when: inventory_hostname != groups['masters'][0] and node_type == "master"

- name: Create a directory ${HOME}/.kube if it does not exist
  file:
    path: ${HOME}/.kube/
    state: directory
    mode: '0755'
  when: node_type == "master"

- name: Copy the /etc/kubernetes/admin.conf to ${HOME}/.kube/config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: ${HOME}/.kube/config
    remote_src: yes
  when: node_type == "master"

- name: Copy the /etc/kubernetes/admin.conf to local machine(path - {{ kubeconfig_path }})
  fetch:
    src: /etc/kubernetes/admin.conf
    dest: "{{ kubeconfig_path }}"
    flat: yes
  when: node_type == "master"

- name: remove taint
  command: "kubectl taint nodes --all node-role.kubernetes.io/control-plane-; kubectl taint nodes --all node-role.kubernetes.io/master-"
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: node_type == "master" and not ('workers' in groups and groups['workers'])

- name: Get the kubeadm join command from the Kubernetes master.
  command: kubeadm token create --print-join-command
  changed_when: false
  when: node_type == "master"
  register: kubernetes_join_command_result

- name: Set the kubeadm join command globally.
  set_fact:
    kubernetes_join_command: >
      {{ kubernetes_join_command_result.stdout }}
  when: kubernetes_join_command_result.stdout is defined
  delegate_to: "{{ item }}"
  delegate_facts: true
  with_items: "{{ groups['all'] }}"

- name: kubeadm join worker nodes
  command: "{{ kubernetes_join_command }}"
  when: node_type == "worker"
